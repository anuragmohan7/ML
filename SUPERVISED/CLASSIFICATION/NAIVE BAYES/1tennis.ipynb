{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple program\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values are inputted,\n",
    "#here you not need to do training,testing,normalization because it is a small dataset\n",
    "outlook=['sunny','sunny','overcast','rainy','rainy','rainy',\n",
    "         'overcast','sunny','sunny','rainy','sunny',\n",
    "         'overcast','overcast','rainy']  #\n",
    "temperature=['hot','hot','hot','mild','cool','cool','cool','mild',\n",
    "             'cool','mild','mild','mild','hot','mild']\n",
    "humidity=['high','high','high','high','normal','normal',\n",
    "          'normal','high','normal','normal','normal','high','normal','high']\n",
    "\n",
    "wind=['weak','strong','weak','weak','weak','strong','strong','weak',\n",
    "      'weak','weak','strong','strong','weak','strong']\n",
    "\n",
    "play=['no','no','yes','yes','yes','no','yes','no','yes','yes',\n",
    "      'yes','yes','yes','no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the datatypes of input values are object, we should encode data\n",
    "#three encoding methods are:\n",
    "#1) Label Encoding ===> machine convert each object to random numeric value in a column\n",
    "#                           drawback of label encoding is a hierarchy is formed here randomly,In order to overcome this we use onehot\n",
    "\n",
    "#2) Onehot Encoding ===> One-hot encoding is a method used to convert categorical data into a numerical format that machine learning algorithms can process. \n",
    "#                           It represents each category as a binary vector, where only one element is \"hot\" (1), and the rest are \"cold\" (0).\n",
    "#                           eg)  column vegetable contains five vegetables If we use one hot Encoding,Vegetable column will disappearand five new columns will appear\n",
    "#                               drawback of one hot encoding is, if many columns are formed model might overfit\n",
    "\n",
    "#3) Get Dummies ===> In order to overcome The drawbacks of one hot encoding we use get dummies, Get dummies is also similar to one hot encoding,\n",
    "#                      In get dummies The first column is removed But we can predict the value using other columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lab=LabelEncoder()\n",
    "outlook_encode=lab.fit_transform(outlook)\n",
    "temp_encode=lab.fit_transform(temperature)\n",
    "humid_encode=lab.fit_transform(humidity)\n",
    "wind_encode=lab.fit_transform(wind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.int64(2), np.int64(1), np.int64(0), np.int64(1)),\n",
       " (np.int64(2), np.int64(1), np.int64(0), np.int64(0)),\n",
       " (np.int64(0), np.int64(1), np.int64(0), np.int64(1)),\n",
       " (np.int64(1), np.int64(2), np.int64(0), np.int64(1)),\n",
       " (np.int64(1), np.int64(0), np.int64(1), np.int64(1)),\n",
       " (np.int64(1), np.int64(0), np.int64(1), np.int64(0)),\n",
       " (np.int64(0), np.int64(0), np.int64(1), np.int64(0)),\n",
       " (np.int64(2), np.int64(2), np.int64(0), np.int64(1)),\n",
       " (np.int64(2), np.int64(0), np.int64(1), np.int64(1)),\n",
       " (np.int64(1), np.int64(2), np.int64(1), np.int64(1)),\n",
       " (np.int64(2), np.int64(2), np.int64(1), np.int64(0)),\n",
       " (np.int64(0), np.int64(2), np.int64(0), np.int64(0)),\n",
       " (np.int64(0), np.int64(1), np.int64(1), np.int64(1)),\n",
       " (np.int64(1), np.int64(2), np.int64(0), np.int64(0))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining all columns\n",
    "features=list(zip(outlook_encode,temp_encode,humid_encode,wind_encode))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "#naive bayes algorithm\n",
    "\n",
    "# in knn algorithm only 1 classifier is present\n",
    "# in naive bayes algorithm, 3 types of classifiers are their\n",
    "\n",
    "#1) Gaussian() ===> used when if the data is continous (all data are numeric)\n",
    "#2) Multinomial() ===> used when if the data is discret (data contains objects)\n",
    "#3) Bernouli() ===> used in both situation (it is used when negative values object are present in data, soo Multinomial not work )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no']\n"
     ]
    }
   ],
   "source": [
    "#here we use Multinomial(), because data contains objects\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(features,play)\n",
    "\n",
    "#predict output of given values\n",
    "print(model.predict([[2,0,0,0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
